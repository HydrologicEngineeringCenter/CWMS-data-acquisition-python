{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Lower Mississippi River Forecast Center - NAEFS Forecast** \n",
    "The following is a Jupyter Notebook to walk through the steps required to set up the getLMRFC_NAEFS script. \n",
    "\n",
    "Currently the script grabs the LMRFC NAEFS Forecast at the following URL: https://tgftp.nws.noaa.gov/data/rfc/lmrfc/misc/\n",
    "\n",
    "There are several set-up requirements that must be done prior.\n",
    "\n",
    "## Create/Ensure all Locations are in CWMS\n",
    "Ensure that all locations needed from the LMRFC NAEFS forecast have been added to the CWMS database. These include sub-locations for local inflows. For Example, the Mississippi River at Memphis, TN uses the *MS126* location in CWMS. So *MS126* and *MS126-LCL* both are added to the CWMS database. *LCL* is a sub location to *MS126*. \n",
    "### NWS Handbook 5 Locations\n",
    "Locations that are not Local inflows, e.g., MEMT1LCL, Need to be added to the Location group, *NWS Handbook 5*, found under *Agency Aliases*, in the *Location Groups* tab in CWMS.\n",
    " \n",
    "![image.png](attachment:image.png)\n",
    "\n",
    "The LMRFC location ID must be added in the Alias column for all gages of interest that are not _LCL ID's.\n",
    "### LMRFC NAEFSLCL Locations\n",
    "Locations for local inflows are added to a second group. This location group will need to be added to the database in CWMS-Vue. Create a new location category called, *LMRFC*, and a location group called, *NAEFS LCL*, as shown below:\n",
    "\n",
    "![image-2.png](attachment:image-2.png)\n",
    "![image-3.png](attachment:image-3.png)\n",
    "\n",
    "## Create/Ensure all Time Series are in CWMS\n",
    "Ensure that all locations from the LMRFC NAEFS forecast have an associated Time Series in CWMS. Make sure that the *Interval Offset* is *Os*. \n",
    "### Default Time Series Group\n",
    "Currently, the script pulls the time series saved in the Default Time Series Group as shown below:\n",
    "![image-4.png](attachment:image-4.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The getLMRFC_NAEFS.py Script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Call Necessary Libraries\n",
    "import requests\n",
    "import gzip\n",
    "import io\n",
    "import logging\n",
    "import json\n",
    "import cwms\n",
    "import datetime\n",
    "import pytz\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xml.etree.ElementTree as ET\n",
    "from bs4 import BeautifulSoup\n",
    "from getpass import getpass\n",
    "from argparse import ArgumentParser, ArgumentDefaultsHelpFormatter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Set Up Parser Arguments\n",
    "parser = ArgumentParser(formatter_class=ArgumentDefaultsHelpFormatter)\n",
    "parser.add_argument(\"-o\", \"--office\", required=True, type=str, help=\"Office to grab data for (Required).\")\n",
    "parser.add_argument(\"-a\", \"--api_root\", required=True, type=str, help=\"Api Root for CDA (Required).\")\n",
    "parser.add_argument(\"-k\", \"--api_key\", default=None, type=str, help=\"api key. one of api_key or api_key_loc are required\")\n",
    "parser.add_argument(\"-kl\", \"--api_key_loc\", default=None, type=str, help=\"file storing Api Key. One of api_key or api_key_loc are required\")\n",
    "args = vars(parser.parse_args())\n",
    "\n",
    "## Create Logger for Logging\n",
    "logger = logging.getLogger()\n",
    "if (logger.hasHandlers()):\n",
    "    logger.handlers.clear()\n",
    "handler = logging.StreamHandler()\n",
    "formatter = logging.Formatter(\n",
    "    \"%(asctime)s;%(levelname)s;%(message)s\", \"%Y-%m-%d %H:%M:%S\")\n",
    "handler.setFormatter(formatter)\n",
    "logger.addHandler(handler)\n",
    "logger.setLevel(logging.INFO)\n",
    "logger.propagate = False\n",
    "storErr = []\n",
    "\n",
    "## Set Up the API\n",
    "OFFICE = args[\"office\"]\n",
    "APIROOT = args[\"api_root\"]\n",
    "\n",
    "if args[\"api_key_loc\"] is not None:\n",
    "    api_key_loc = args[\"api_key_loc\"]\n",
    "    with open(api_key_loc, \"r\") as f:\n",
    "        APIKEY = f.readline().strip()\n",
    "elif args[\"api_key\"] is not None:\n",
    "    APIKEY=args[\"api_key\"]\n",
    "else:\n",
    "    raise Exception(\"must add a value to either --api_key(-a) or --api_key_loc(-al)\")\n",
    "apiKey = \"apikey \" + APIKEY\n",
    "api = cwms.api.init_session(api_root=APIROOT, api_key=apiKey)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define Necessary Functions/Arguments\n",
    "# Missing Values in CWMS\n",
    "Missing_Value = -340282346638528859811704183484516925440\n",
    "Missing_Quality_Code = 5\n",
    "\n",
    "#Goes to https://tgftp.nws.noaa.gov/data/rfc/lmrfc/misc/ and Gets the NAEFS 28-Day PI XML Forecast\n",
    "def get_NAEFS_PIXML():\n",
    "    logger.info(f\"Searching for Most Recent LMRFC NAEFS Forecast at https://tgftp.nws.noaa.gov/data/rfc/lmrfc/misc/\")\n",
    "    #A Required Function\n",
    "    def extract_number_from_href(href):\n",
    "        start_index = href.find(partial_query) + len(partial_query)  # Find the index right after the string\n",
    "        number = int(href[start_index+1:start_index+1+14])  # Extract the number as an integer\n",
    "        return number\n",
    "    \n",
    "    #Calls LMRFC tgftp Site\n",
    "    page_url = \"https://tgftp.nws.noaa.gov/data/rfc/lmrfc/misc/\"\n",
    "    page_response = requests.get(page_url)\n",
    "    page_soup = BeautifulSoup(page_response.content, \"html.parser\")\n",
    "    \n",
    "    # Grabs the Correct NAEFS Product\n",
    "    partial_query = \"HECRAS_NAEFS_pixml_export\"\n",
    "    query = f\"a[href*=\\'{partial_query}\\']\" \n",
    "    wrong_elements = page_soup.select(query)\n",
    "    elements = [element for element in wrong_elements if element.get('href').endswith(\".gz\")]\n",
    "    \n",
    "    #Creates a Variable with the Most Recent Version\n",
    "    if elements:\n",
    "        element_with_largest_number = max(elements, key=lambda x: extract_number_from_href(x['href']))\n",
    "        logger.info(f\"SUCCESS Found NAEFS Forecast as File Name --> {element_with_largest_number}\")\n",
    "    else:\n",
    "        utc_datetime = datetime.datetime.utcnow()\n",
    "        formatted_datetime = utc_datetime.strftime('%Y-%m-%d %H:%M:%S %Z')\n",
    "        logger.info(f\"ERROR: No NAEFS Forecast Found! Script Aborted at: {formatted_datetime}\")\n",
    "        sys.exit(1)\n",
    "    \n",
    "    #Saves the Most Recent NAEFS Forecast PI XML File \n",
    "    file_url = \"https://tgftp.nws.noaa.gov/data/rfc/lmrfc/misc/\"+element_with_largest_number[\"href\"]\n",
    "    logger.info(f\"Grabbing NAEFS Forecast at --> {file_url}\")\n",
    "\n",
    "    #Un-Zip the File\n",
    "    response = requests.get(file_url)\n",
    "    response.raise_for_status()\n",
    "    compressed_file = io.BytesIO(response.content)\n",
    "    with gzip.GzipFile(fileobj=compressed_file, mode='rb') as f:\n",
    "        xml_data = f.read().decode('utf-8')\n",
    "    \n",
    "    # Create an in-memory BytesIO object\n",
    "    xml_file = io.BytesIO(xml_data.encode('utf-8'))\n",
    "    logger.info(f\"SUCCESS PI XML File Ready\")\n",
    "    return xml_file\n",
    "\n",
    "#Parses Supplied PI XML File, Saves Data Based on Supplied Time Series and Location Groups, and Writes to CDA\n",
    "\n",
    "#Gets Time Series and Location Group Alias Information and Combines to a Single Data Frame\n",
    "def get_CWMS_TS_Loc_Data(office):\n",
    "    # Create a DF with the Time series in the \"Default\" TS Group\n",
    "    df = cwms.get_timeseries_group(group_id=\"Default\",category_id=\"Default\",office_id=\"CWMS\").df\n",
    "\n",
    "    # Format the DF\n",
    "    df[[\"location-id\", \"param\", \"type\", \"int\", \"dur\", \"ver\"]] = df[\"timeseries-id\"].str.split(\".\", expand=True)\n",
    "    df = df[df[\"office-id\"] == office]\n",
    "    df[\"base-loc\"] = df[\"location-id\"].str.split(\"-\", expand=True)[0]\n",
    "    if \"alias-id\" not in df.columns:\n",
    "        df[\"alias-id\"] = np.nan\n",
    "    if \"attribute\" not in df.columns:\n",
    "        df[\"attribute\"] = np.nan\n",
    "    df = df.rename(columns={\"alias-id\": \"NWS_Method_TS\"})\n",
    "    \n",
    "    # Grab the Location Group Information\n",
    "    #NWS Handbook 5 Locations\n",
    "    Locdf = cwms.get_location_group(loc_group_id=\"NWS Handbook 5 ID\",category_id=\"Agency Aliases\",office_id=\"CWMS\").df.set_index('location-id')\n",
    "    Locdf = Locdf[Locdf[\"office-id\"] == office]\n",
    "\n",
    "    NWS_alias_1 = Locdf[Locdf[\"alias-id\"].notnull()]\n",
    "    NWS_alias_1 = NWS_alias_1.rename(\n",
    "        columns={\"alias-id\": \"NWS_St_Num\", \"attribute\": \"Loc_attribute\"}\n",
    "    )\n",
    "\n",
    "    #LMRFC NAEFS Local Flow Locations\n",
    "    Locdf = cwms.get_location_group(loc_group_id=\"NAEFS LCL\",category_id=\"LMRFC\",office_id=office).df.set_index('location-id')\n",
    "    Locdf = Locdf[Locdf[\"office-id\"] == office]\n",
    "    NWS_alias_2 = Locdf[Locdf[\"alias-id\"].notnull()]\n",
    "    NWS_alias_2 = NWS_alias_2.rename(\n",
    "        columns={\"alias-id\": \"NWS_St_Num\", \"attribute\": \"Loc_attribute\"}\n",
    "    )\n",
    "\n",
    "    #Merge the Two NWS Locations Together\n",
    "    NWS_alias = pd.concat([NWS_alias_1,NWS_alias_2], axis=0)\n",
    "\n",
    "    # Merge the TS to the NWS Locations\n",
    "    NWS_ts = pd.merge(df, NWS_alias, how=\"left\",\n",
    "                       on=[\"location-id\", \"office-id\"])\n",
    "    NWS_ts_base = pd.merge(\n",
    "        NWS_ts[NWS_ts.NWS_St_Num.isnull()].drop(\n",
    "            [\"NWS_St_Num\", \"Loc_attribute\"], axis=1\n",
    "        ),\n",
    "        NWS_alias,\n",
    "        left_on=[\"base-loc\", \"office-id\"],\n",
    "        right_on=[\"location-id\", \"office-id\"],\n",
    "    )\n",
    "    NWS_ts = pd.concat(\n",
    "        [NWS_ts[NWS_ts[\"NWS_St_Num\"].notnull()], NWS_ts_base], axis=0\n",
    "    )\n",
    "\n",
    "    #Simplify for Later Use\n",
    "    df = NWS_ts\n",
    "    LocTS_df = df[['NWS_St_Num','location-id','param','timeseries-id']]\n",
    "    return LocTS_df\n",
    "\n",
    "#Grabs Parsed Data from the PI XML File, Converts it to JSON, and Saves to CDA\n",
    "def load_NAEFS_data(row,LocTS_df,NS,creationDate,creationTime,root):\n",
    "    # Grab some Variables\n",
    "    site_location = row[1].upper()\n",
    "    USACE_site = row[2]\n",
    "    site_parameter = row[3].upper()\n",
    "    site_timeseries = row[4]\n",
    "    logger.info(f\"Checking for Data at --> {site_location}\")\n",
    "\n",
    "    #Find the NWS Station and appropriate associated parameter\n",
    "    for series in root.findall('pi:series',NS):\n",
    "        #Parse Headers\n",
    "        header = series.find('pi:header',NS)\n",
    "        NWS_Location = header.find('pi:locationId',NS).text\n",
    "        Parameter = header.find('pi:parameterId',NS).text\n",
    "        Units = header.find('pi:units',NS).text\n",
    "        NWS_Missing = header.find('pi:missVal',NS).text\n",
    "\n",
    "        if NWS_Location == site_location and Parameter == site_parameter:\n",
    "            logger.info(f\"SUCCESS Found Data for --> {site_location}\")\n",
    "            x = 1\n",
    "            #Get Creation Date for Version Time Series\n",
    "            forecast_datetime = creationDate+\" \"+creationTime\n",
    "            forecast_datetime = datetime.datetime.strptime(forecast_datetime,'%Y-%m-%d %H:%M:%S')\n",
    "            forecast_datetime = forecast_datetime.replace(hour=12,minute=0,second=0)\n",
    "            \n",
    "            #Format the Forecast Date to Use as the Version Date\n",
    "            forecast_tz = pytz.timezone('UTC')\n",
    "            forecast_datetime = forecast_datetime.astimezone(forecast_tz)\n",
    "            forecast_datetime = forecast_datetime.strftime('%Y-%m-%dT%H:%M:%S%z')\n",
    "\n",
    "            #Grab the Actual Data\n",
    "            logger.info(f\"Saving data as --> {USACE_site} to TSID --> {site_timeseries}\")\n",
    "            dateTimes = []\n",
    "            values = []\n",
    "            qualities = []\n",
    "            for event in series.findall('pi:event',NS):\n",
    "                date = event.get('date')\n",
    "                time = event.get('time')\n",
    "                Datetime = f\"{date} {time}\"\n",
    "                value = event.get('value')\n",
    "                quality = 0\n",
    "                if value == NWS_Missing:\n",
    "                    value = Missing_Value\n",
    "                    quality = Missing_Quality_Code\n",
    "                dateTimes.append(Datetime)\n",
    "                values.append(value)\n",
    "                qualities.append(quality)\n",
    "            \n",
    "            #Convert to a Pandas Data Frame and Add the Quality Code\n",
    "            data_df = pd.DataFrame({'date-time':dateTimes,'value':values,'quality-code':qualities})\n",
    "\n",
    "            #Format the Datetime Column\n",
    "            data_df['date-time'] = pd.to_datetime(data_df[\"date-time\"])\n",
    "            data_df['date-time'] = data_df['date-time'].dt.tz_localize('UTC')\n",
    "            data_df['date-time'] = data_df['date-time'].dt.strftime(\"%Y-%m-%d %H:%M:%S%z\")\n",
    "\n",
    "            #Write Data to CDA\n",
    "            logger.info(f\"Writing Data to CDA for --> {site_location}\")\n",
    "            try:\n",
    "                data_json = cwms.timeseries_df_to_json(data=data_df,ts_id=site_timeseries,units=Units,office_id=OFFICE,version_date=forecast_datetime)\n",
    "                cwms.store_timeseries(data_json)\n",
    "                logger.info(\n",
    "                    f\"SUCCESS Forecast Stored in CWMS Database for --> {site_location},{site_timeseries}\"\n",
    "                )\n",
    "            except Exception as error:\n",
    "                storErr.append([site_timeseries,error])\n",
    "                logger.error(\n",
    "                    f\"FAIL Forecast Could not be Stored in CWMS Database for --> {site_location},{site_timeseries}. CDA Error --> {error}\"\n",
    "                )\n",
    "            break #Ends the search for row, the NWS Site Location, in the PI XML File\n",
    "        else:\n",
    "            x = 0\n",
    "    if x == 0:\n",
    "        logger.info(f\"WARNING No Data Found for --> {site_location}\")\n",
    "\n",
    "#Runs the Main Script Call\n",
    "def main():\n",
    "    #Some Admin/TimeStamp Stuff\n",
    "    utc_datetime = datetime.datetime.utcnow()\n",
    "    formatted_datetime = utc_datetime.strftime('%Y-%m-%d %H:%M:%S %Z')\n",
    "    logger.info(f\"Script Call was Initialed at: {formatted_datetime}\")\n",
    "    logger.info(f\"CDA Connection: {APIROOT}\")\n",
    "\n",
    "    # Get the PI XML File and Parse It\n",
    "    xml_file = get_NAEFS_PIXML()\n",
    "    \n",
    "    # Grab the Location and Time Series Groups\n",
    "    LocTS_df = get_CWMS_TS_Loc_Data(OFFICE)\n",
    "    logger.info(f\"The Following Locations will be Saved to the Specified Time Series: {LocTS_df}\")\n",
    "    \n",
    "    # Specify Namespace and Grab XML Root\n",
    "    NS = {'pi': 'http://www.wldelft.nl/fews/PI'}\n",
    "    tree = ET.parse(xml_file)\n",
    "    root = tree.getroot()\n",
    "\n",
    "    # Grab a Single Creation Date & Time to Use for All Locations\n",
    "    for series in root.findall('pi:series',NS):\n",
    "        header = series.find('pi:header',NS)\n",
    "        try:\n",
    "            creationDate = header.find('pi:creationDate', NS).text\n",
    "            creationTime = header.find('pi:creationTime', NS).text\n",
    "            break\n",
    "        except:\n",
    "            logger.info(f\"There are no Creation Date or Time in the Entire PI XML File\")\n",
    "    logger.info(f\"Found the following Creation Date & Time --> {creationDate},{creationTime}\")\n",
    "    \n",
    "    #Loop Through Locations and Get Data to Save via CDA\n",
    "    for row in LocTS_df.itertuples():\n",
    "        load_NAEFS_data(row,LocTS_df,NS,creationDate,creationTime,root)\n",
    "    \n",
    "    #Log When the Script Ended\n",
    "    utc_datetime = datetime.datetime.utcnow()\n",
    "    formatted_datetime = utc_datetime.strftime('%Y-%m-%d %H:%M:%S %Z')\n",
    "    logger.info(f\"Script Call Ended at: {formatted_datetime}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Runs the Command\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env-cwms",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
